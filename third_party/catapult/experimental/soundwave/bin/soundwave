#!/usr/bin/env python
# Copyright 2018 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

import argparse
import csv
import json
import logging
import oauth2client.tools
import os
import sys

SOUNDWAVE_ROOT_PATH = os.path.normpath(os.path.join(
    os.path.dirname(__file__), '..'))
PY_UTILS_PATH = os.path.normpath(os.path.join(
    SOUNDWAVE_ROOT_PATH, '..', '..', 'common', 'py_utils'))

sys.path.append(SOUNDWAVE_ROOT_PATH)
sys.path.append(PY_UTILS_PATH)

from soundwave import alert_model
from soundwave import dashboard_api
from soundwave import database


# For help creating service account credentials see:
# https://developers.google.com/api-client-library/python/auth/service-accounts#creatinganaccount

DATABASE_SCHEMA_PATH = os.path.join(
    SOUNDWAVE_ROOT_PATH, 'soundwave', 'schema.sql')
DEFAULT_USER_CREDENTIALS_PATH = os.path.join(
    SOUNDWAVE_ROOT_PATH, 'user-credentials.json')
DEFAULT_DATABASE_PATH = os.path.join(
    SOUNDWAVE_ROOT_PATH, 'soundwave.db')


def GetBugData(dashboard_communicator, bug):
  """Returns data for given bug."""
  if not bug:
    return {'bug': {'state': None, 'status': None, 'summary': None}}
  if int(bug) == -1:
    return {'bug': {'state': None, 'status': None, 'summary': 'Invalid'}}
  if int(bug) == -2:
    return {'bug': {'state': None, 'status': None, 'summary': 'Ignored'}}

  data = dashboard_communicator.GetBugData(bug)
  # Only care about date of comments, not content.
  data['bug']['comments'] = [a['published'] for a in data['bug']['comments']]
  return data


def FetchAlertsData(args):
  # TODO(#4293): Add test coverage.
  dashboard_communicator = dashboard_api.PerfDashboardCommunicator(args)
  alerts = dashboard_communicator.GetAlertData(
      args.benchmark, args.days)['anomalies']
  print '%s alerts found!' % len(alerts)

  with database.Database(args.database_file, DATABASE_SCHEMA_PATH) as db:
    for alert in alerts:
      db.Put(alert_model.Alert.FromJson(alert))

  return
  # TODO(#4281): Also fetch and store bug data.
  bug_list = set([a.get('bug_id') for a in alerts])
  print 'Collecting data for %d bugs.' % len(bug_list)
  bugs = {}
  for bug in bug_list:
    bugs[bug] = GetBugData(dashboard_communicator, bug)['bug']

  data = {'bugs': bugs, 'alerts': alerts}
  with open(args.output_path, 'w') as fp:
    print 'Saving data to %s.' % args.output_path
    json.dump(data, fp, sort_keys=True, indent=2)


def FetchTimeseriesData(args):
  dashboard_communicator = dashboard_api.PerfDashboardCommunicator(args)
  with open(args.output_path, 'wb') as fp:
    csv_writer = csv.writer(fp)
    for row in dashboard_communicator.GetAllTimeseriesForBenchmark(
        args.benchmark, args.days, args.filters):
      csv_writer.writerow(row)


def Main():
  logging.basicConfig(level=logging.INFO)

  # Args for API access.
  parser = argparse.ArgumentParser(parents=[oauth2client.tools.argparser])
  parser.add_argument(
      '--service-account-json',
      help=('Path to json credentials file for a service account. Falls back '
            'to user credentials if not provided.'))
  parser.add_argument(
      '--user-credentials-json', default=DEFAULT_USER_CREDENTIALS_PATH,
      help='Path to file where to store user credentials')
  # Default args for all actions.
  parser.add_argument(
      '-b', '--benchmark', required=True, help='Benchmark to pull data for.')
  parser.add_argument(
      '-d', '--days', default=30, type=int,
      help='Number of days to collect data for (default: %(default)s)')
  subparsers = parser.add_subparsers(dest='action')
  subparsers.required = True
  # Subparser args for fetching alerts data.
  subparser = subparsers.add_parser('alerts')
  subparser.add_argument(
      '--database-file', default=DEFAULT_DATABASE_PATH,
      help='File path for database where to store data.')
  # Subparser args for fetching timeseries data.
  subparser = subparsers.add_parser('timeseries')
  subparser.add_argument(
      '--output-path', default='timeseries_data.csv',
      help='File path where to save output. (default: %(default)s)')
  subparser.add_argument(
      '-f', '--filters', action='append',
      help=('Only get data for timeseries whose path contains all the given '
            'substrings.'))

  args = parser.parse_args()
  if args.action == 'alerts':
    FetchAlertsData(args)
  elif args.action == 'timeseries':
    FetchTimeseriesData(args)
  else:
    raise NotImplementedError(args.action)


if __name__ == '__main__':
  Main()
